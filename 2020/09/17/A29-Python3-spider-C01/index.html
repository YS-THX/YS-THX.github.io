<!--      　　　___           ___           ___           ___           ___                    ___           ___       ___           ___     
　　　　　　   /\  \         /\  \         /\__\         |\__\         /\  \                  /\  \         /\__\     /\  \         /\  \    
  　　　　　　 \:\  \       /::\  \       /:/  /         |:|  |       /::\  \                /::\  \       /:/  /    /::\  \       /::\  \   
          　　  \:\  \     /:/\:\  \     /:/__/          |:|  |      /:/\ \  \              /:/\:\  \     /:/  /    /:/\:\  \     /:/\:\  \  
          　　  /::\  \   /::\~\:\  \   /::\  \ ___      |:|__|__   _\:\~\ \  \            /::\~\:\__\   /:/  /    /:/  \:\  \   /:/  \:\  \ 
          　　 /:/\:\__\ /:/\:\ \:\__\ /:/\:\  /\__\ ____/::::\__\ /\ \:\ \ \__\          /:/\:\ \:|__| /:/__/    /:/__/ \:\__\ /:/__/_\:\__\
        　　  /:/  \/__/ \/_|::\/:/  / \/__\:\/:/  / \::::/~~/~    \:\ \:\ \/__/          \:\~\:\/:/  / \:\  \    \:\  \ /:/  / \:\  /\ \/__/
        　　 /:/  /         |:|::/  /       \::/  /   ~~|:|~~|      \:\ \:\__\             \:\ \::/  /   \:\  \    \:\  /:/  /   \:\ \:\__\  
        　　 \/__/          |:|\/__/        /:/  /      |:|  |       \:\/:/  /              \:\/:/  /     \:\  \    \:\/:/  /     \:\/:/  /  
        　　                |:|  |         /:/  /       |:|  |        \::/  /                \::/__/       \:\__\    \::/  /       \::/  /   
        　　                 \|__|         \/__/         \|__|         \/__/                  ~~            \/__/     \/__/         \/__/    

   ┌───┐   ┌───┬───┬───┬───┐   ┌───┬───┬───┬───┐   ┌───┬───┬───┬───┐  ┌───┬───┬───┐
   │ Esc  │   │  F1  │  F2  │  F3  │  F4  │   │  F5  │  F6  │  F7  │  F8  │   │  F9  │ F10  │ F11  │ F12  │  │ P/S  │ S L  │ P/B  │
   └───┘   └───┴───┴───┴───┘   └───┴───┴───┴───┘   └───┴───┴───┴───┘  └───┴───┴───┘
   ┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───────┐ ┌───┬───┬───┐
   │ ~ `  │ ! 1  │ @ 2  │ # 3  │ $ 4  │ % 5  │ ^ 6  │ & 7  │ * 8  │ ( 9  │ ) 0  │ _ -  │ + =  │    BacSp     │ │ Ins  │ Hom  │ PUp  │
   ├───┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─────┤ ├───┼───┼───┤
   │   Tab    │  Q   │  W   │  E   │  R   │  T   │  Y   │  U   │  I   │  O   │  P   │ { [  │ } ]  │   | \    │ │ Del  │ End  │ PDn  │
   ├─────┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴─────┤ └───┴───┴───┘
   │    Caps    │  A   │  S   │  D   │  F   │  G   │  H   │  J   │  K   │  L   │ : ;  │ " '  │     Enter      │
   ├──────┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴────────┤         ┌───┐
   │     Shift      │  Z   │  X   │  C   │  V   │  B   │  N   │  M   │ < ,  │ > .  │ ? /  │       Shift        │         │  ↑  │
   ├─────┬──┴─┬─┴──┬┴───┴───┴───┴───┴───┴──┬┴───┼───┴┬────┬────┤ ┌───┼───┼───┐
   │   Ctrl   │        │  Alt   │                     Space                    │   Alt  │   Fn   │   ＝   │  Ctrl  │ │  ←  │  ↓  │  →  │
   └─────┴────┴────┴───────────────────────┴────┴────┴────┴────┘ └───┴───┴───┘

              写字楼里写字间，写字间里程序员；程序人员写程序，又拿程序换酒钱。酒醒只在网上坐，酒醉还来网下眠；酒醉酒醒日复日，网上网下年复年。
              但愿老死电脑间，不愿鞠躬老板前；奔驰宝马贵者趣，公交自行程序员。别人笑我忒疯癫，我笑自己命太贱；不见满街漂亮妹，哪个归得程序员？
-->
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="google-site-verification" content="nZLRt2TSr_hyrtOpExvCPWYNAt_QT0NsctUkGqjvOgo" />
  
  <title>Python3 爬虫学习笔记 C01 | YS-THX</title>
  
  

  

  <meta name="HandheldFriendly" content="True" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <!-- meta -->
  
  
  <meta name='theme-color' content='#f24e32'>
  <meta name='msapplication-TileColor' content='#f24e32'>
  <meta name='msapplication-config' content='https://cdn.jsdelivr.net/gh/xaoxuu/assets@master/favicon/favicons/browserconfig.xml'>
  
  <!-- 360 -->
  <meta name="360-site-verification" content="d98acd5dccc92e495179410dd58186be" />
  <!-- 360自动收录 -->
  <script>
    (function () {
      var src = "https://jspassport.ssl.qhimg.com/11.0.1.js?d182b3f28525f2db83acfaaf6e696dba";
      document.write('<script src="' + src + '" id="sozz"><\/script>');
    })();
  </script>
  <!-- sogou -->
  <meta name="sogou_site_verification" content="l0yGeAV56W" />
  <!-- link -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-waves@0.7.6/dist/waves.min.css">
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.6.3/css/all.min.css">
  
  
  <link rel='shortcut icon' type='image/x-icon' href='https://cdn.jsdelivr.net/gh/TRHX/CDN-for-itrhx.com@3.0.4/images/favicon.ico'>
  <link rel='icon' type='image/x-icon' sizes='32x32' href='https://cdn.jsdelivr.net/gh/TRHX/CDN-for-itrhx.com@3.0.4/images/favicon-32x32.png'>
  <link rel='apple-touch-icon' type='image/png' sizes='180x180' href='https://cdn.jsdelivr.net/gh/TRHX/CDN-for-itrhx.com@3.0.4/images/apple-touch-icon.png'>
  <link rel='mask-icon' color='#f24e32' href='https://cdn.jsdelivr.net/gh/TRHX/CDN-for-itrhx.com@3.0.4/images/safari-pinned-tab.svg'>
  <link rel='manifest' href='https://cdn.jsdelivr.net/gh/xaoxuu/cdn-favicon@19.9.7/site.webmanifest'>
  

  
  <link rel="shortcut icon" type='image/x-icon' href="https://cdn.jsdelivr.net/gh/TRHX/CDN-for-itrhx.com@3.0.4/images/favicon.ico">
  

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/TRHX/CDN-for-itrhx.com@3.1.0/css/style.css">

  

  <script>
    function setLoadingBarProgress(num) {
      document.getElementById('loading-bar').style.width = num + "%";
    }
  </script>

  
  
  <!-- Google Adsense -->
  <!--<script data-ad-client="ca-pub-1913211097936916" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>-->
<meta name="generator" content="Hexo 5.1.1"></head>
<body>
  
  
<div class="cover-wrapper">
  <cover class='cover post half'>
    
    
  <h1 class='title'>YS-THX'S BLOG</h1>


  <div class="m_search">
    <form name="searchform" class="form u-search-form">
      <input type="text" class="input u-search-input" placeholder="世界之大，探索一下！" />
      <i class="icon fas fa-search fa-fw"></i>
    </form>
  </div>

<div class='menu navgation'>
  <ul class='h-list'>
    
      
        <li>
          <a class="nav home" href="/"
            
            
            id="home">
            <i class='fas fa-home fa-fw'></i>&nbsp;主页
          </a>
        </li>
      
        <li>
          <a class="nav home" href="/categories/"
            
            
            id="categories">
            <i class='fas fa-folder-open fa-fw'></i>&nbsp;分类
          </a>
        </li>
      
        <li>
          <a class="nav home" href="/tags/"
            
            
            id="tags">
            <i class='fas fa-tags fa-fw'></i>&nbsp;标签
          </a>
        </li>
      
        <li>
          <a class="nav home" href="/friends/"
            
            
            id="friends">
            <i class='fas fa-users fa-fw'></i>&nbsp;朋友
          </a>
        </li>
      
        <li>
          <a class="nav home" href="/comments/"
            
            
            id="comments">
            <i class='fas fa-comments fa-fw'></i>&nbsp;留言
          </a>
        </li>
      
    
  </ul>
</div>

    
    <br>
    <!-- Hitokoto 一言 -->
    <!--<p id="hitokoto"></p>
			<script src="https://cdn.jsdelivr.net/npm/bluebird@3/js/browser/bluebird.min.js"></script>
			<script src="https://cdn.jsdelivr.net/npm/whatwg-fetch@2.0.3/fetch.min.js"></script>
      <script src="https://v1.hitokoto.cn/?encode=js&select=%23hitokoto" defer></script>-->
    <!-- 打字特效 -->
    <script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11"></script>
    <div style="text-align: center;font-weight: bold;color: #1BC3FB;">
      <span id="subtitle"></span>
      <span id="typed-cursor"></span>
    </div>
    <script>
      var typed = new Typed("#subtitle", { strings: ["Live a good life, write some good code !!!", "愿自己的努力终将获得回报。", "花开不是为了花落，而是为了开的更加灿烂。", "没有伞的孩子必须努力奔跑！", "欲望以提升热忱，毅力以磨平高山。", "如果放弃太早，你永远都不知道自己会错过什么。", "没有礁石，就没有美丽的浪花；没有挫折，就没有壮丽的人生。"], startDelay: 1000, typeSpeed: 100, loop: !0, backSpeed: 60, backDelay: 2000, showCursor: !0 })
    </script>
  </cover>
  <header class="l_header pure">
  <div id="loading-bar-wrapper">
    <div id="loading-bar" class="pure"></div>
  </div>

	<div class='wrapper'>
		<div class="nav-main container container--flex">
      <a class="logo flat-box" href='/' >
        
          YS-THX
        
      </a>
			<div class='menu navgation'>
				<ul class='h-list'>
          
  					
  						<li>
								<a class="nav flat-box" href="/"
                  
                  
                  id="home">
									<i class='fas fa-home fa-fw'></i>&nbsp;主页
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/archives/"
                  
                  
                  id="archives">
									<i class='fas fa-archive fa-fw'></i>&nbsp;归档
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/friends/"
                  
                  
                  id="friends">
									<i class='fas fa-users fa-fw'></i>&nbsp;朋友
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/comments/"
                  
                  
                  id="comments">
									<i class='fas fa-comments fa-fw'></i>&nbsp;留言
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/about/"
                  
                  
                    target="_blank"
                  
                  id="about">
									<i class='fas fa-info-circle fa-fw'></i>&nbsp;关于
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="/box/"
                  
                  
                    target="_blank"
                  
                  id="box">
									<i class='fas fa-tools fa-fw'></i>&nbsp;百宝箱
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="https://mi.aliyun.com/shop/40012"
                  
                  
                    target="_blank"
                  
                  id="https:mi.aliyun.comshop40012">
									<i class='fas fa-link fa-fw'></i>&nbsp;米店
								</a>
							</li>
      			
  						<li>
								<a class="nav flat-box" href="http://cov.itrhx.com/"
                  
                  
                    target="_blank"
                  
                  id="http:cov.itrhx.com">
									<i class='fas fa-heart fa-fw'></i>&nbsp;肺炎疫情图
								</a>
							</li>
      			
      		
				</ul>
			</div>

			
				<div class="m_search">
					<form name="searchform" class="form u-search-form">
						<input type="text" class="input u-search-input" placeholder="Search" />
						<i class="icon fas fa-search fa-fw"></i>
					</form>
				</div>
			
			<ul class='switcher h-list'>
				
					<li class='s-search'><a class="fas fa-search fa-fw" href='javascript:void(0)'></a></li>
				
				<li class='s-menu'><a class="fas fa-bars fa-fw" href='javascript:void(0)'></a></li>
			</ul>
		</div>

		<div class='nav-sub container container--flex'>
			<a class="logo flat-box"></a>
			<ul class='switcher h-list'>
				<li class='s-comment'><a class="flat-btn fas fa-comments fa-fw" href='javascript:void(0)'></a></li>
        
          <li class='s-toc'><a class="flat-btn fas fa-list fa-fw" href='javascript:void(0)'></a></li>
        
			</ul>
		</div>
	</div>
</header>
	<aside class="menu-phone">
    <header>
		<nav class="menu navgation">
      <ul>
        
          
            <li>
							<a class="nav flat-box" href="/"
                
                
                id="home">
								<i class='fas fa-home fa-fw'></i>&nbsp;主页
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/archives/"
                
                
                id="archives">
								<i class='fas fa-archive fa-fw'></i>&nbsp;归档
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/friends/"
                
                
                id="friends">
								<i class='fas fa-users fa-fw'></i>&nbsp;朋友
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/comments/"
                
                
                id="comments">
								<i class='fas fa-comments fa-fw'></i>&nbsp;留言
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" target="_blank" rel="noopener" href="https://mi.aliyun.com/shop/40012"
                
                
                id="https:mi.aliyun.comshop40012">
								<i class='fas fa-link fa-fw'></i>&nbsp;米店
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" href="/box/"
                
                
                id="box">
								<i class='fas fa-tools fa-fw'></i>&nbsp;百宝箱
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" target="_blank" rel="noopener" href="https://itrhx.blog.csdn.net/"
                
                
                id="https:itrhx.blog.csdn.net">
								<i class='fab fa-cuttlefish fa-fw'></i>&nbsp;CSDN
							</a>
            </li>
          
            <li>
							<a class="nav flat-box" target="_blank" rel="noopener" href="http://cov.itrhx.com/"
                
                
                id="http:cov.itrhx.com">
								<i class='fas fa-heart fa-fw'></i>&nbsp;肺炎疫情图
							</a>
            </li>
          
       
      </ul>
		</nav>
    </header>
	</aside>
<script>setLoadingBarProgress(40);</script>

</div>

  <div class="l_body">
    <div class='body-wrapper'>
      <div class='l_main'>
  

  
    <article id="post" class="post white-box article-type-post" itemscope itemprop="blogPost">
      


  <section class='meta'>
    
    
      <a title='Python3 爬虫学习笔记 C01' href='/2020/09/17/A29-Python3-spider-C01/'><img class='thumbnail' src='https://cdn.jsdelivr.net/gh/TRHX/ImageHosting/ITRHX-PIC/thumbnail/spider.png'></a>
    
    <div class="meta" id="header-meta">
      
        
  
    <h1 class="title">
      <a href="/2020/09/17/A29-Python3-spider-C01/">
        Python3 爬虫学习笔记 C01
      </a>
    </h1>
  


      
      <div class='new-meta-box'>
        
          
        
          
            
  <div class='new-meta-item author'>
    <a href="https://ys-thx.github.io" rel="nofollow">
      
        <img src="https://cdn.jsdelivr.net/gh/YS-THX/ImageHost/YS-PIC/6ad063c19cf362ccdc33e011f364df0.png">
      
      <p>YS-THX</p>
    </a>
  </div>


          
        
          
            <div class="new-meta-item date">
  <a class='notlink'>
    <i class="fas fa-calendar-alt" aria-hidden="true"></i>
    <p>2020-09-17</p>
  </a>
</div>

          
        
          
            
  
  <div class='new-meta-item category'>
    <a href='/categories/Python3-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0/' rel="nofollow">
      <i class="fas fa-folder-open" aria-hidden="true"></i>
      <p>Python3 学习笔记&nbsp;/&nbsp;爬虫学习</p>
    </a>
  </div>


          
        
          
            
  
    <div class="new-meta-item browse busuanzi">
      <a class='notlink'>
        <i class="fas fa-eye" aria-hidden="true"></i>
        <p>
          <span id="busuanzi_value_page_pv">
            <i class="fas fa-spinner fa-spin fa-fw" aria-hidden="true"></i>
          </span>
        </p>
      </a>
    </div>
  


          
        
          
            
  
    <div class="new-meta-item wordcount">
      <a class='notlink'>
        <i class="fas fa-keyboard" aria-hidden="true"></i>
        <p>字数统计:</p>
        <p>3.8k字</p>
      </a>
    </div>
    <div class="new-meta-item readtime">
      <a class='notlink'>
        <i class="fas fa-hourglass-half" aria-hidden="true"></i>
        <p>阅读时长≈</p>
        <p>17分</p>
      </a>
    </div>
  

          
        
          
            

          
        
      </div>
      
        <hr>
      
    </div>
  </section>


      <section class="article typo">
        <div class="article-entry" itemprop="articleBody">
          <blockquote>
<center><font color=#1BC3FB size=4>Python3 爬虫学习笔记第一章 ——【基本库 urllib 的使用】</font></center>
</blockquote>
<a id="more"></a>

<h1 id="【1-1】-urllib-简介"><a href="#【1-1】-urllib-简介" class="headerlink" title=" 【1.1】 urllib 简介"></a><font color=#FF0000> 【1.1】 urllib 简介</font></h1><p>在 Python 中有两种方式可以发送 HTTP 请求，分别是自带的 urllib 库和第三方的 requests 库</p>
<blockquote>
<p>urllib 库：Python 内置的 HTTP 请求库，无需额外安装即可使用；Python 2 中有 urllib 和 urllib2 两个库来实现请求的发送，Python 3 中统一为 urllib。官方文档：<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/urllib.html">https://docs.python.org/3/library/urllib.html</a></p>
</blockquote>
<p><font color=#FF0000>urllib 所包含的常用模块：</font></p>
<ul>
<li>urllib.request：模拟发送请求；</li>
<li>urllib.error：异常处理模块，用于捕获异常；</li>
<li>urllib.parse：解析、拆分、合并URL；</li>
<li>urllib.robotparser：读取网站的 robots.txt 文件，判断哪些内容可以爬取。</li>
</ul>
<p><font color=#FF0000>urllib.request 所包含的常用方法：</font></p>
<ul>
<li>urllib.request.urlopen()：打开网址URL，这可以是一个字符串或一个 Request对象；</li>
<li>urllib.request.Request()：在请求的时候传入一些 headers 等信息；</li>
<li>urllib.request.urlretrieve()：将获取的URL的内容写到文件目录中去。</li>
</ul>
<p><font color=#FF0000>urllib.error 所包含的两个异常：</font></p>
<ul>
<li>URLError：继承自 OSError 类，是 error 异常模块的基类，由 request 模块产生的异常都可以通过捕获这个类来处理。</li>
<li>HTTPError：是 URLError 的子类，专门用来处理 HTTP 请求错误，比如认证请求失败等。</li>
</ul>
<p><font color=#FF0000>urllib.parse 所包含的常用方法：</font></p>
<ul>
<li>urllib.parse.urlencode()：将字典参数序列化为 GET 请求参数；</li>
<li>urllib.parse.parse_qs()：将 GET 请求参数反序列化转回字典；</li>
<li>urllib.parse.parse_qsl()：将参数转化为元组组成的列表；</li>
<li>urllib.parse.urlparse()：对 URL 进行分段（返回6个结果）；</li>
<li>urllib.parse.urlunparse()：对 URL 进行组合（长度必须为6）；</li>
<li>urllib.parse.urlsplit()：对 URL 进行分段（不单独解析params部分，返回5个结果）；</li>
<li>urllib.parse.urlunsplit()：对 URL 进行组合（长度必须为5）；</li>
<li>urllib.parse.urljoin()：对 URL 进行组合（没有长度限制，给定两个参数，自动分析 scheme、netloc 和 path 这 3 个内容并对新链接缺失的部分进行补充，最后返回结果）；</li>
<li>urllib.parse.quote()：将内容转化为 URL 编码格式；</li>
<li>urllib.parse.unquote()：对 URL 进行解码。</li>
</ul>
<p><font color=#FF0000>urllib.robotparser 所包含的类：</font></p>
<ul>
<li>RobotFileParser：根据网站的 robots.txt 文件来判断一个爬取爬虫是否有权限来爬取这个网页</li>
</ul>
<h1 id="【1-2】-urllib-request-发送请求"><a href="#【1-2】-urllib-request-发送请求" class="headerlink" title=" 【1.2】 urllib.request 发送请求"></a><font color=#FF0000> 【1.2】 urllib.request 发送请求</font></h1><h2 id="【1-2-1】-urllib-request-urlopen"><a href="#【1-2-1】-urllib-request-urlopen" class="headerlink" title="【1.2.1】 urllib.request.urlopen()"></a><font color=#FF0000>【1.2.1】 urllib.request.urlopen()</font></h2><h3 id="【1-2-1-1】-基本使用方法"><a href="#【1-2-1-1】-基本使用方法" class="headerlink" title="【1.2.1.1】 基本使用方法"></a><font color=#FF0000>【1.2.1.1】 基本使用方法</font></h3><p>urlopen() 函数的 API：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">urllib.request.urlopen(url, data=<span class="literal">None</span>, [timeout,]*, cafile=<span class="literal">None</span>, capath=<span class="literal">None</span>, cadefault=<span class="literal">False</span>, context=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>基本使用：运行以下代码可得到 <a target="_blank" rel="noopener" href="https://www.itrhx.com/">https://www.itrhx.com/</a> 的网页源代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(<span class="string">&#x27;https://www.itrhx.com/&#x27;</span>)</span><br><span class="line">print(response.read().decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br></pre></td></tr></table></figure>
<p>输出响应对象的类型和属性：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(<span class="string">&#x27;https://www.itrhx.com/&#x27;</span>)</span><br><span class="line">print(type(response))            <span class="comment"># 响应类型</span></span><br><span class="line">print(response.status)           <span class="comment"># 返回结果的状态码，200代表请求成功</span></span><br><span class="line">print(response.getheaders())       <span class="comment"># 响应的头信息</span></span><br><span class="line">print(response.getheader(<span class="string">&#x27;Server&#x27;</span>))  <span class="comment"># 获取响应头的 server 值</span></span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">http</span>.<span class="title">client</span>.<span class="title">HTTPResponse</span>&#x27;&gt;</span></span><br><span class="line"><span class="class">200</span></span><br><span class="line">[(&#x27;Content-Type&#x27;, &#x27;text/html; charset=utf-8&#x27;), (&#x27;Server&#x27;, &#x27;GitHub.com&#x27;), (&#x27;Last-Modified&#x27;, &#x27;Sat, 17 Aug 2019 12:16:48 GMT&#x27;), (&#x27;ETag&#x27;, &#x27;&quot;5d57f030-10863&quot;&#x27;), (&#x27;Access-Control-Allow-Origin&#x27;, &#x27;*&#x27;), (&#x27;Expires&#x27;, &#x27;Sat, 17 Aug 2019 19:41:25 GMT&#x27;), (&#x27;Cache-Control&#x27;, &#x27;max-age=600&#x27;), (&#x27;X-Proxy-Cache&#x27;, &#x27;MISS&#x27;), (&#x27;X-GitHub-Request-Id&#x27;, &#x27;C748:735D:5B7461:619B95:5D58560B&#x27;), (&#x27;Content-Length&#x27;, &#x27;67683&#x27;), (&#x27;Accept-Ranges&#x27;, &#x27;bytes&#x27;), (&#x27;Date&#x27;, &#x27;Sun, 18 Aug 2019 13:28:44 GMT&#x27;), (&#x27;Via&#x27;, &#x27;1.1 varnish&#x27;), (&#x27;Age&#x27;, &#x27;228&#x27;), (&#x27;Connection&#x27;, &#x27;close&#x27;), (&#x27;X-Served-By&#x27;, &#x27;cache-tyo19931-TYO&#x27;), (&#x27;X-Cache&#x27;, &#x27;HIT&#x27;), (&#x27;X-Cache-Hits&#x27;, &#x27;1&#x27;), (&#x27;X-Timer&#x27;, &#x27;S1566134924.190474,VS0,VE0&#x27;), (&#x27;Vary&#x27;, &#x27;Accept-Encoding&#x27;), (&#x27;X-Fastly-Request-ID&#x27;, &#x27;25a69f8130fc9cae412d28990a724543d7d05e8b&#x27;)]</span><br><span class="line">GitHub.com</span><br></pre></td></tr></table></figure>
<h3 id="【1-2-1-2】-添加参数"><a href="#【1-2-1-2】-添加参数" class="headerlink" title="【1.2.1.2】 添加参数"></a><font color=#FF0000>【1.2.1.2】 添加参数</font></h3><p>根据 urlopen() 函数的 API 可知，除了最基本的 URL 参数以外，我们还可以传递其他内容，比如 data（附加数据）、timeout（超时时间）等，以下用 data 和 timeout 参数举例说明。</p>
<h4 id="●-data-参数"><a href="#●-data-参数" class="headerlink" title="● data 参数"></a><font color=#FF0000>● data 参数</font></h4><p>如果要添加 data 参数，需要使用 bytes 方法将参数转化为字节流编码格式的内容，即 bytes 类型。另外，如果传递了这个参数，则它的请求方式就不再是 GET 方式，而是 POST 方式。代码示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">data = bytes(urllib.parse.urlencode(&#123;<span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;hello&#x27;</span>&#125;), encoding=<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line">response = urllib.request.urlopen(<span class="string">&#x27;http://httpbin.org/post&#x27;</span>, data=data)</span><br><span class="line">print(response.read())</span><br></pre></td></tr></table></figure>
<p>httpbin.org 站点提供 HTTP 请求测试，<a target="_blank" rel="noopener" href="http://httpbin.org/post">http://httpbin.org/post</a> 用于测试 POST 请求，示例中传递一个值为 hello 的 word 参数。使用 bytes 方法，将其转码成 bytes（字节流）类型。该方法的第一个参数需要是 str（字符串）类型，需要用 urllib.parse 模块里的 urlencode 方法来将参数字典转化为字符串；第二个参数指定编码格式为 utf8，运行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">b&#x27;&#123;</span></span><br><span class="line"><span class="string">	&quot;args&quot;: &#123;&#125;,</span></span><br><span class="line"><span class="string">	&quot;data&quot;: &quot;&quot;, </span></span><br><span class="line"><span class="string">	&quot;files&quot;: &#123;&#125;,</span></span><br><span class="line"><span class="string">	&quot;form&quot;: &#123;</span></span><br><span class="line"><span class="string">		&quot;word&quot;: &quot;hello&quot;</span></span><br><span class="line"><span class="string">	&#125;,</span></span><br><span class="line"><span class="string">	&quot;headers&quot;: &#123;</span></span><br><span class="line"><span class="string">		&quot;Accept-Encoding&quot;: &quot;identity&quot;, </span></span><br><span class="line"><span class="string">		&quot;Content-Length&quot;: &quot;10&quot;,</span></span><br><span class="line"><span class="string">		&quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;,</span></span><br><span class="line"><span class="string">		&quot;Host&quot;: &quot;httpbin.org&quot;,</span></span><br><span class="line"><span class="string">		&quot;User-Agent&quot;: &quot;Python-urllib/3.6&quot;</span></span><br><span class="line"><span class="string">	&#125;, </span></span><br><span class="line"><span class="string">	&quot;json&quot;: null, </span></span><br><span class="line"><span class="string">	&quot;origin&quot;: &quot;171.115.101.10, 171.115.101.10&quot;, </span></span><br><span class="line"><span class="string">	&quot;url&quot;: &quot;https://httpbin.org/post&quot;</span></span><br><span class="line"><span class="string">&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<h4 id="●-timeout-参数"><a href="#●-timeout-参数" class="headerlink" title="● timeout 参数"></a><font color=#FF0000>● timeout 参数</font></h4><p>举例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(<span class="string">&#x27;http://httpbin.org/get&#x27;</span>, timeout=<span class="number">0.1</span>)  </span><br><span class="line">print(response.read())</span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">During handling of the above exception, another exception occurred:</span><br><span class="line"></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;C:/Users/Lenovo/Desktop/1.py&quot;</span>, line <span class="number">2</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    response = urllib.request.urlopen(<span class="string">&#x27;http://httpbin.org/get&#x27;</span>, timeout=<span class="number">0.1</span>)</span><br><span class="line"> ...</span><br><span class="line">urllib.error.URLError: &lt;urlopen error timed out&gt;</span><br></pre></td></tr></table></figure>
<p>timeout 设置为0.1，0.1秒过后服务器没有响应，便会抛出 URLError 异常<br>进阶：使用 try except 语句抛出异常</p>
<h2 id="【1-2-2】-urllib-request-Request"><a href="#【1-2-2】-urllib-request-Request" class="headerlink" title="【1.2.2】 urllib.request.Request()"></a><font color=#FF0000>【1.2.2】 urllib.request.Request()</font></h2><p>Request() 方法可以在请求的时候传入一些 data、headers 等信息<br>Request() 的构造方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">urllib</span>.<span class="title">request</span>.<span class="title">Request</span>(<span class="params">url, data=None, headers=&#123;&#125;, origin_req_host=None, unverifiable=False, method=None</span>)</span></span><br></pre></td></tr></table></figure>
<p>构造方法各个参数的解释：</p>
<ul>
<li><p>url：用于请求 URL，这是必传参数，其他都是可选参数。</p>
</li>
<li><p>data：如果要传，必须传 bytes（字节流）类型的。如果它是字典，可以先用 urllib.parse 模块里的 urlencode() 编码。</p>
</li>
<li><p>headers：是一个字典，它就是请求头，可以在构造请求时通过 headers 参数直接构造，也可以通过调用请求实例的 add_header() 方法添加。添加请求头最常用的用法就是通过修改 User-Agent 来伪装浏览器，默认的 User-Agent 是 Python-urllib，我们可以通过修改它来伪装浏览器。</p>
</li>
<li><p>origin_req_host：指的是请求方的 host 名称或者 IP 地址。</p>
</li>
<li><p>unverifiable：表示这个请求是否是无法验证的，默认是 False，意思就是说用户没有足够权限来选择接收这个请求的结果。例如，我们请求一个 HTML 文档中的图片，但是我们没有自动抓取图像的权限，这时 unverifiable 的值就是 True。</p>
</li>
<li><p>method：是一个字符串，用来指示请求使用的方法，比如 GET、POST 和 PUT 等。</p>
</li>
</ul>
<p>简单举例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://www.baidu.com/&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定制要伪装的头部</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 构建请求对象</span></span><br><span class="line">request = urllib.request.Request(url=url, headers=headers)</span><br><span class="line"><span class="comment"># 发送请求</span></span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line">print(response.read().decode())</span><br></pre></td></tr></table></figure>

<h2 id="【1-2-3】-urllib-request-urlretrieve"><a href="#【1-2-3】-urllib-request-urlretrieve" class="headerlink" title="【1.2.3】 urllib.request.urlretrieve()"></a><font color=#FF0000>【1.2.3】 urllib.request.urlretrieve()</font></h2><p>将获取到的 URL 内容保存到当前文件夹，简单举例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://www.itrhx.com/images/trhx.png&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># response = urllib.request.urlopen(image_url)</span></span><br><span class="line"><span class="comment"># with open(&#x27;trhx.png&#x27;, &#x27;wb&#x27;) as fp:</span></span><br><span class="line"><span class="comment">#    fp.write(response.read())</span></span><br><span class="line"></span><br><span class="line">urllib.request.urlretrieve(url, <span class="string">&#x27;trhx.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h1 id="【1-3】-urllib-error-异常处理"><a href="#【1-3】-urllib-error-异常处理" class="headerlink" title=" 【1.3】 urllib.error 异常处理"></a><font color=#FF0000> 【1.3】 urllib.error 异常处理</font></h1><h2 id="【1-3-1】-URLError"><a href="#【1-3-1】-URLError" class="headerlink" title="【1.3.1】 URLError"></a><font color=#FF0000>【1.3.1】 URLError</font></h2><p>如果打开一个不存在的页面，就会出现 URLError 错误，该错误有一个 reason 属性，用于返回错误的原因。简单举例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request, error  </span><br><span class="line"><span class="keyword">try</span>:  </span><br><span class="line">    response = request.urlopen(<span class="string">&#x27;https://www.itrhx.com/index/&#x27;</span>)  </span><br><span class="line"><span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:  </span><br><span class="line">    print(e.reason)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Not Found</span><br></pre></td></tr></table></figure>

<h2 id="【1-3-2】-HTTPError"><a href="#【1-3-2】-HTTPError" class="headerlink" title="【1.3.2】 HTTPError"></a><font color=#FF0000>【1.3.2】 HTTPError</font></h2><p>URLError 的子类，专门用来处理 HTTP 请求错误，比如认证请求失败等。它有如下3个属性：</p>
<ul>
<li>code：返回 HTTP 状态码，比如 404 表示网页不存在，500 表示服务器内部错误等。</li>
<li>reason：同父类一样，用于返回错误的原因。</li>
<li>headers：返回请求头。</li>
</ul>
<p>简单举例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request, error  </span><br><span class="line"><span class="keyword">try</span>:  </span><br><span class="line">    response = request.urlopen(<span class="string">&#x27;https://www.itrhx.com/index/&#x27;</span>)  </span><br><span class="line"><span class="keyword">except</span> error.HTTPError <span class="keyword">as</span> e:  </span><br><span class="line">    print(e.code, e.reason, e.headers)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">404</span> Not Found Content-Type: text/html; charset=utf<span class="number">-8</span></span><br><span class="line">Server: GitHub.com</span><br><span class="line">ETag: <span class="string">&quot;5d57f030-7f2&quot;</span></span><br><span class="line">Access-Control-Allow-Origin: *</span><br><span class="line">X-Proxy-Cache: MISS</span><br><span class="line">X-GitHub-Request-Id: <span class="number">4</span>B46:<span class="number">2</span>F5D:<span class="number">6</span>DE0F1:<span class="number">755</span>BB2:<span class="number">5</span>D5964C5</span><br><span class="line">Content-Length: <span class="number">2034</span></span><br><span class="line">Accept-Ranges: bytes</span><br><span class="line">Date: Sun, <span class="number">18</span> Aug <span class="number">2019</span> <span class="number">14</span>:<span class="number">50</span>:<span class="number">41</span> GMT</span><br><span class="line">Via: <span class="number">1.1</span> varnish</span><br><span class="line">Age: <span class="number">252</span></span><br><span class="line">Connection: close</span><br><span class="line">X-Served-By: cache-tyo19951-TYO</span><br><span class="line">X-Cache: HIT</span><br><span class="line">X-Cache-Hits: <span class="number">1</span></span><br><span class="line">X-Timer: S1566139842<span class="number">.563134</span>,VS0,VE0</span><br><span class="line">Vary: Accept-Encoding</span><br><span class="line">X-Fastly-Request-ID: e9eb0a507be66a866bfaa7c5cc2e1c53b1f7ccab</span><br></pre></td></tr></table></figure>
<h2 id="【1-3-3】-进阶用法"><a href="#【1-3-3】-进阶用法" class="headerlink" title="【1.3.3】 进阶用法"></a><font color=#FF0000>【1.3.3】 进阶用法</font></h2><p>因为 URLError 是 HTTPError 的父类，所以可以先选择捕获子类的错误，再去捕获父类的错误，前面的代码改进：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request, error  </span><br><span class="line">​</span><br><span class="line"><span class="keyword">try</span>:  </span><br><span class="line">    response = request.urlopen(<span class="string">&#x27;https://www.itrhx.com/index/&#x27;</span>)  </span><br><span class="line"><span class="keyword">except</span> error.HTTPError <span class="keyword">as</span> e:  </span><br><span class="line">    print(e.reason, e.code, e.headers)  </span><br><span class="line"><span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:  </span><br><span class="line">    print(e.reason)  </span><br><span class="line"><span class="keyword">else</span>:  </span><br><span class="line">    print(<span class="string">&#x27;Request Successfully&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="【1-4】-urllib-parse-解析-URL"><a href="#【1-4】-urllib-parse-解析-URL" class="headerlink" title=" 【1.4】 urllib.parse 解析 URL"></a><font color=#FF0000> 【1.4】 urllib.parse 解析 URL</font></h1><h2 id="【1-4-1】-urllib-parse-urlencode"><a href="#【1-4-1】-urllib-parse-urlencode" class="headerlink" title="【1.4.1】 urllib.parse.urlencode()"></a><font color=#FF0000>【1.4.1】 urllib.parse.urlencode()</font></h2><p>将字典参数序列化为 GET 请求参数，示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode</span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;ie&#x27;</span>: <span class="string">&#x27;utf-8&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;wd&#x27;</span>: <span class="string">&#x27;TRHX&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line">base_url = <span class="string">&#x27;http://www.baidu.com?&#x27;</span></span><br><span class="line">url = base_url + urlencode(data)</span><br><span class="line">print(url)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://www.baidu.com?ie=utf-8&amp;wd=TRHX</span><br></pre></td></tr></table></figure>

<h2 id="【1-4-2】-urllib-parse-parse-qs"><a href="#【1-4-2】-urllib-parse-parse-qs" class="headerlink" title="【1.4.2】 urllib.parse.parse_qs()"></a><font color=#FF0000>【1.4.2】 urllib.parse.parse_qs()</font></h2><p>与 urlencode() 相反，将 GET 请求参数反序列化转回字典，示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> parse_qs</span><br><span class="line">query = <span class="string">&#x27;name=TRHX&amp;age=20&#x27;</span></span><br><span class="line">print(parse_qs(query))</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;name&#x27;</span>: [<span class="string">&#x27;TRHX&#x27;</span>], <span class="string">&#x27;age&#x27;</span>: [<span class="string">&#x27;20&#x27;</span>]&#125;</span><br></pre></td></tr></table></figure>

<h2 id="【1-4-3】-urllib-parse-parse-qsl"><a href="#【1-4-3】-urllib-parse-parse-qsl" class="headerlink" title="【1.4.3】 urllib.parse.parse_qsl()"></a><font color=#FF0000>【1.4.3】 urllib.parse.parse_qsl()</font></h2><p>将参数转化为元组组成的列表，示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> parse_qsl</span><br><span class="line">query = <span class="string">&#x27;name=TRHX&amp;age=20&#x27;</span></span><br><span class="line">print(parse_qsl(query))</span><br></pre></td></tr></table></figure>
<p>输出 结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[(<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;TRHX&#x27;</span>), (<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;20&#x27;</span>)]</span><br></pre></td></tr></table></figure>
<h2 id="【1-4-4】-urllib-parse-urlparse"><a href="#【1-4-4】-urllib-parse-urlparse" class="headerlink" title="【1.4.4】 urllib.parse.urlparse()"></a><font color=#FF0000>【1.4.4】 urllib.parse.urlparse()</font></h2><p>对 URL 进行分段，返回 6 个结果，示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlparse</span><br><span class="line">result = urlparse(<span class="string">&#x27;http://www.baidu.com/index.html;user?id=5#comment&#x27;</span>)</span><br><span class="line">print(type(result), result)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="class"><span class="keyword">class</span> &#x27;<span class="title">urllib</span>.<span class="title">parse</span>.<span class="title">ParseResult</span>&#x27;&gt; <span class="title">ParseResult</span>(<span class="params">scheme=<span class="string">&#x27;http&#x27;</span>, netloc=<span class="string">&#x27;www.baidu.com&#x27;</span>, path=<span class="string">&#x27;/index.html&#x27;</span>, params=<span class="string">&#x27;user&#x27;</span>, query=<span class="string">&#x27;id=5&#x27;</span>, fragment=<span class="string">&#x27;comment&#x27;</span></span>)</span></span><br></pre></td></tr></table></figure>
<p>返回结果为 ParseResult 类型的对象，含 scheme、netloc、path、params、query 和 fragment 6 个部分，依次代表协议、域名、路径、参数、查询条件、锚点</p>
<h2 id="【1-4-5】-urllib-parse-urlunparse"><a href="#【1-4-5】-urllib-parse-urlunparse" class="headerlink" title="【1.4.5】 urllib.parse.urlunparse()"></a><font color=#FF0000>【1.4.5】 urllib.parse.urlunparse()</font></h2><p>与 urlparse() 相反，对 URL 进行组合，传入的参数是一个可迭代对象，长度必须是 6，否则会抛出参数数量不足或者过多的问题，示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlunparse  </span><br><span class="line">data = [<span class="string">&#x27;http&#x27;</span>, <span class="string">&#x27;www.baidu.com&#x27;</span>, <span class="string">&#x27;index.html&#x27;</span>, <span class="string">&#x27;user&#x27;</span>, <span class="string">&#x27;a=6&#x27;</span>, <span class="string">&#x27;comment&#x27;</span>]  </span><br><span class="line">print(urlunparse(data))</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://www.baidu.com/index.html;user?a=6#comment</span><br></pre></td></tr></table></figure>

<h2 id="【1-4-6】-urllib-parse-urlsplit"><a href="#【1-4-6】-urllib-parse-urlsplit" class="headerlink" title="【1.4.6】 urllib.parse.urlsplit()"></a><font color=#FF0000>【1.4.6】 urllib.parse.urlsplit()</font></h2><p>与 urlparse() 方法相似，但是它不再单独解析 params 部分，只返回 5 个结果。params 会合并到 path 中，示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlsplit  </span><br><span class="line">result = urlsplit(<span class="string">&#x27;http://www.baidu.com/index.html;user?id=5#comment&#x27;</span>)  </span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SplitResult(scheme=<span class="string">&#x27;http&#x27;</span>, netloc=<span class="string">&#x27;www.baidu.com&#x27;</span>, path=<span class="string">&#x27;/index.html;user&#x27;</span>, query=<span class="string">&#x27;id=5&#x27;</span>, fragment=<span class="string">&#x27;comment&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="【1-4-7】-urllib-parse-urlunsplit"><a href="#【1-4-7】-urllib-parse-urlunsplit" class="headerlink" title="【1.4.7】 urllib.parse.urlunsplit()"></a><font color=#FF0000>【1.4.7】 urllib.parse.urlunsplit()</font></h2><p>与 urlunparse() 方法类似，对 URL 进行组合，传入的参数也是一个可迭代对象，长度必须为 5，示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlunsplit  </span><br><span class="line">data = [<span class="string">&#x27;http&#x27;</span>, <span class="string">&#x27;www.baidu.com&#x27;</span>, <span class="string">&#x27;index.html&#x27;</span>, <span class="string">&#x27;a=6&#x27;</span>, <span class="string">&#x27;comment&#x27;</span>]  </span><br><span class="line">print(urlunsplit(data))</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://www.baidu.com/index.html?a=6#comment</span><br></pre></td></tr></table></figure>

<h2 id="【1-4-8】-urllib-parse-urljoin"><a href="#【1-4-8】-urllib-parse-urljoin" class="headerlink" title="【1.4.8】 urllib.parse.urljoin()"></a><font color=#FF0000>【1.4.8】 urllib.parse.urljoin()</font></h2><p>对 URL 进行组合，提供两个 URL 作为两个参数，将会自动分析 URL 的 scheme、netloc 和 path 这 3 个内容并对新链接缺失的部分进行补充，最后返回结果，示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urljoin  </span><br><span class="line">print(urljoin(<span class="string">&#x27;http://www.baidu.com&#x27;</span>, <span class="string">&#x27;friends.html&#x27;</span>))  </span><br><span class="line">print(urljoin(<span class="string">&#x27;http://www.baidu.com&#x27;</span>, <span class="string">&#x27;https://www.itrhx.com/friends.html&#x27;</span>))  </span><br><span class="line">print(urljoin(<span class="string">&#x27;http://www.baidu.com/friends.html&#x27;</span>, <span class="string">&#x27;https://www.itrhx.com/friends.html&#x27;</span>))  </span><br><span class="line">print(urljoin(<span class="string">&#x27;http://www.baidu.com/friends.html&#x27;</span>, <span class="string">&#x27;https://www.itrhx.com/friends.html?id=2&#x27;</span>))  </span><br><span class="line">print(urljoin(<span class="string">&#x27;http://www.baidu.com?wd=trhx&#x27;</span>, <span class="string">&#x27;https://www.itrhx.com/index.html&#x27;</span>))  </span><br><span class="line">print(urljoin(<span class="string">&#x27;http://www.baidu.com&#x27;</span>, <span class="string">&#x27;?category=2#comment&#x27;</span>))  </span><br><span class="line">print(urljoin(<span class="string">&#x27;www.baidu.com&#x27;</span>, <span class="string">&#x27;?category=2#comment&#x27;</span>))  </span><br><span class="line">print(urljoin(<span class="string">&#x27;www.baidu.com#comment&#x27;</span>, <span class="string">&#x27;?category=2&#x27;</span>))</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">http://www.baidu.com/friends.html</span><br><span class="line">https://www.itrhx.com/friends.html</span><br><span class="line">https://www.itrhx.com/friends.html</span><br><span class="line">https://www.itrhx.com/friends.html?id=2</span><br><span class="line">https://www.itrhx.com/index.html</span><br><span class="line">http://www.baidu.com?category=2#comment</span><br><span class="line">www.baidu.com?category=2#comment</span><br><span class="line">www.baidu.com?category=2</span><br></pre></td></tr></table></figure>

<h2 id="【1-4-9】-urllib-parse-quote"><a href="#【1-4-9】-urllib-parse-quote" class="headerlink" title="【1.4.9】 urllib.parse.quote()"></a><font color=#FF0000>【1.4.9】 urllib.parse.quote()</font></h2><p>将内容转化为 URL 编码的格式。当 URL 中带有中文参数时，可以将中文字符转化为 URL 编码，示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> quote</span><br><span class="line">keyword = <span class="string">&#x27;中国&#x27;</span>  </span><br><span class="line">url = <span class="string">&#x27;https://www.baidu.com/s?wd=&#x27;</span> + quote(keyword)  </span><br><span class="line">print(url)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.baidu.com/s?wd=%E4%B8%AD%E5%9B%BD</span><br></pre></td></tr></table></figure>

<h2 id="【1-4-10】-urllib-parse-unquote"><a href="#【1-4-10】-urllib-parse-unquote" class="headerlink" title="【1.4.10】 urllib.parse.unquote()"></a><font color=#FF0000>【1.4.10】 urllib.parse.unquote()</font></h2><p>与 quote() 方法相反，对 URL 进行解码，示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> unquote  </span><br><span class="line">url = <span class="string">&#x27;https://www.baidu.com/s?wd=%E4%B8%AD%E5%9B%BD&#x27;</span>  </span><br><span class="line">print(unquote(url))</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.baidu.com/s?wd=中国</span><br></pre></td></tr></table></figure>

<h1 id="【1-5】-urllib-robotparser-爬取权限判断"><a href="#【1-5】-urllib-robotparser-爬取权限判断" class="headerlink" title=" 【1.5】 urllib.robotparser 爬取权限判断"></a><font color=#FF0000> 【1.5】 urllib.robotparser 爬取权限判断</font></h1><h2 id="【1-5-1】-Robots-协议简介"><a href="#【1-5-1】-Robots-协议简介" class="headerlink" title="【1.5.1】 Robots 协议简介"></a><font color=#FF0000>【1.5.1】 Robots 协议简介</font></h2><blockquote>
<p>Robots 协议即爬虫协议，用来告诉爬虫和搜索引擎哪些页面可以抓取，哪些不可以抓取。它通常是一个叫作 robots.txt 的文本文件，一般放在网站的根目录下。</p>
</blockquote>
<p>robots.txt 基本格式：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">User-agent:</span><br><span class="line">Disallow:</span><br><span class="line">Allow:</span><br></pre></td></tr></table></figure>
<ul>
<li>User-agent 为搜索爬虫的名称，设置为 * 则表示对任何爬虫皆有效；</li>
<li>Disallow 指定了不允许抓取的目录，设置为 / 则代表不允许抓取所有页面；</li>
<li>Allow 指定了允许抓取的目录，一般和 Disallow 一起使用，一般不会单独使用，用来排除某些限制。</li>
</ul>
<p>一些常见的搜索爬虫名称及其对应的网站：</p>
<table>
<thead>
<tr>
<th>爬虫名称</th>
<th>网站名称</th>
<th>网站地址</th>
</tr>
</thead>
<tbody><tr>
<td>BaiduSpider</td>
<td>百度</td>
<td><a target="_blank" rel="noopener" href="http://www.baidu.com/">www.baidu.com</a></td>
</tr>
<tr>
<td>Googlebot</td>
<td>谷歌</td>
<td><a target="_blank" rel="noopener" href="http://www.google.com/">www.google.com</a></td>
</tr>
<tr>
<td>360Spider</td>
<td>360</td>
<td><a target="_blank" rel="noopener" href="http://www.so.com/">www.so.com</a></td>
</tr>
<tr>
<td>Sogouspider</td>
<td>搜狗</td>
<td><a target="_blank" rel="noopener" href="http://www.sogou.com/">www.sogou.com</a></td>
</tr>
<tr>
<td>YodaoBot</td>
<td>有道</td>
<td><a target="_blank" rel="noopener" href="http://www.youdao.com/">www.youdao.com</a></td>
</tr>
<tr>
<td>Bingbot</td>
<td>必应</td>
<td><a target="_blank" rel="noopener" href="http://www.bing.com/">www.bing.com</a></td>
</tr>
<tr>
<td>Yahoo!  Slurp</td>
<td>雅虎</td>
<td><a target="_blank" rel="noopener" href="http://www.yahoo.com/">www.yahoo.com</a></td>
</tr>
<tr>
<td>ia_archiver</td>
<td>Alexa</td>
<td><a target="_blank" rel="noopener" href="http://www.alexa.cn/">www.alexa.cn</a></td>
</tr>
<tr>
<td>Scooter</td>
<td>altavista</td>
<td><a target="_blank" rel="noopener" href="http://www.altavista.com/">www.altavista.com</a></td>
</tr>
</tbody></table>
<h2 id="【1-5-2】-RobotFileParser-类常用方法"><a href="#【1-5-2】-RobotFileParser-类常用方法" class="headerlink" title="【1.5.2】 RobotFileParser 类常用方法"></a><font color=#FF0000>【1.5.2】 RobotFileParser 类常用方法</font></h2><p>RobotFileParser 类的声明：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">urllib.robotparser.RobotFileParser(url=<span class="string">&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>常用方法及其解释：</p>
<ul>
<li><p>set_url：用来设置 robots.txt 文件的链接。如果在创建 RobotFileParser<br>对象时传入了链接，那么就不需要再用这种方法了。</p>
</li>
<li><p>read：读取 robots.txt 文件并进行分析。此方法执行一个读取和分析操作，若不调用此方法，接下来的判断都会为 False，这个方法不会返回任何内容，但是执行了读取操作。</p>
</li>
<li><p>parse：解析 robots.txt 文件，传入的参数是 robots.txt 某些行的内容，它会按照 robots.txt 的语法规则来分析这些内容。</p>
</li>
<li><p>can_fetch：该方法传入两个参数，第一个是 User-agent，第二个是要抓取的 URL。返回的内容是该搜索引擎是否可以抓取这个 URL，返回结果是 True 或 False。</p>
</li>
<li><p>mtime：返回的是上次抓取和分析 robots.txt 的时间，此方法可以定期检查来抓取最新的 robots.txt。</p>
</li>
<li><p>modified：将当前时间设置为上次抓取和分析 robots.txt 的时间。</p>
</li>
</ul>
<p>以简书为例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br